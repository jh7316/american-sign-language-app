# american-sign-language-app
Website for teaching american sign language using hand pose detection.

## ğŸ– HandTalk - Real-Time ASL Recognition
(Replace with an actual image or GIF of your app in action.)

## ğŸ“Œ Overview
HandTalk is a real-time American Sign Language (ASL) recognition application that helps users learn and practice ASL by detecting and classifying hand gestures through their webcam. It leverages computer vision and deep learning to provide instant feedback and track user progress interactively.

The project utilizes TensorFlow.js, HandPose, and Fingerpose for hand detection and classification. The frontend is built using React.js and Chakra UI, offering a seamless user experience with a structured progress-based learning system.

## ğŸš€ Features
âœ… Real-time ASL Alphabet Detection â€“ Uses a deep learning pipeline to classify ASL hand gestures dynamically.
âœ… Interactive Learning System â€“ Step-by-step ASL alphabet training with feedback and animations.
âœ… Gesture Validation System â€“ Highlights correct gestures with a visual confirmation circle.
âœ… Progress Tracking â€“ Users can navigate through the ASL alphabet with a sidebar and progress bar.
âœ… Web-based Application â€“ No installations required; runs entirely in a browser using TensorFlow.js.

## ğŸ— Tech Stack
Frontend: React.js, Chakra UI
Machine Learning: TensorFlow.js, HandPose, Fingerpose
Computer Vision: Hand landmark detection, feature extraction, gesture classification
State Management: React Hooks (useState, useEffect)
UI/UX Enhancements: Animated feedback, real-time progress tracking
ğŸ›  Setup & Installation
To run HandTalk locally, follow these steps:

1ï¸âƒ£ Clone the repository:
 ```
sh
Copy
Edit
git clone https://github.com/yourusername/handtalk-asl.git
cd handtalk-asl
 ```
2ï¸âƒ£ Install dependencies:
 ```
sh
Copy
Edit
npm install
 ```
3ï¸âƒ£ Start the development server:
 ```
sh
Copy
Edit
npm start
 ```
The app will open at http://localhost:3000.

## ğŸ“¸ Screenshots
(Include images/GIFs of the app in action.)

## ğŸ“– How It Works
Enable Webcam â€“ The app accesses the webcam to detect hand gestures.
Gesture Recognition â€“ HandPose detects hand landmarks, and Fingerpose classifies gestures.
Real-time Feedback â€“ If a gesture matches the target ASL letter, a green confirmation circle appears.
Progress Navigation â€“ Users move through the alphabet with a sidebar and progress tracker.
